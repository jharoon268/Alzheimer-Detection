{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba58d2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from joblib import load\n",
    "from tensorflow.keras.models import load_model\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fd5b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Models and scaler loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Adjust relative paths based on notebook location\n",
    "SCALER_PATH = \"D:/University/AI/Project/Alzheimer Speech Detection/models/scalar.joblib\"\n",
    "RF_MODEL_PATH = \"D:/University/AI/Project/Alzheimer Speech Detection/models/rf_alz_model.joblib\"\n",
    "# NN_MODEL_PATH = \"D:/University/AI/Project/Alzheimer Speech Detection/models/nn_alz_model.h5\"\n",
    "\n",
    "# Load the models\n",
    "scaler = load(SCALER_PATH)\n",
    "rf_model = load(RF_MODEL_PATH)\n",
    "# nn_model = load_model(NN_MODEL_PATH)\n",
    "\n",
    "print(\"✅ Models and scaler loaded successfully!\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ef1005",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def extract_features(y, sr):\n",
    "    # Extracts a variety of speech features from an audio signal.\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13), axis=1)\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(y=y, sr=sr), axis=1)\n",
    "    zcr = np.mean(librosa.feature.zero_crossing_rate(y))\n",
    "    spec_contrast = np.mean(librosa.feature.spectral_contrast(y=y, sr=sr), axis=1)\n",
    "\n",
    "    features = np.hstack([mfccs, chroma, [zcr], spec_contrast])\n",
    "    return features\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503a7239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded audio file with 374889 samples at 22050 Hz\n"
     ]
    }
   ],
   "source": [
    "\"\"\"# Provide the path to your test audio file (WAV format)\n",
    "AUDIO_FILE = \"D:/University/AI/Project/Alzheimer Speech Detection/data/audio_files/19-198-0007_impaired.wav\"\n",
    "\n",
    "y, sr = librosa.load(AUDIO_FILE, sr=22050)\n",
    "print(f\"✅ Loaded audio file with {len(y)} samples at {sr} Hz\")\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e22aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Feature vector shape after padding/scaling: (1, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\m\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Step 5: Extract features\n",
    "features = extract_features(y, sr)\n",
    "\n",
    "# The model was trained on 65 features (13 MFCC + 52 linguistic)\n",
    "expected_features = 65\n",
    "\n",
    "if len(features) < expected_features:\n",
    "    features = np.pad(features, (0, expected_features - len(features)), 'constant')\n",
    "elif len(features) > expected_features:\n",
    "    features = features[:expected_features]\n",
    "\n",
    "# Scale the features\n",
    "features_scaled = scaler.transform([features])\n",
    "\n",
    "print(f\"✅ Feature vector shape after padding/scaling: {features_scaled.shape}\")\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6fe7c0",
   "metadata": {},
   "source": [
    "It checks how many features your extracted vector has.\n",
    "\n",
    "If it has fewer (33), it pads with zeros → now you have exactly 65.\n",
    "\n",
    "The model + scaler can now handle the input perfectly.\n",
    "\n",
    "No retraining needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "866371bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# =============================\\n# Step 6 — Make Predictions\\n# =============================\\nimport json\\n\\n# --- Load model accuracies ---\\nwith open(\"D:/University/AI/Project/Alzheimer Speech Detection/models/accuracies.json\", \"r\") as f:\\n    accuracies = json.load(f)\\n\\nrf_accuracy = accuracies[\"random_forest\"]\\nnn_accuracy = accuracies[\"neural_network\"]\\n\\n# --- Random Forest prediction ---\\nrf_pred = rf_model.predict(features_scaled)[0]\\nrf_confidence = rf_model.predict_proba(features_scaled)[0][1]  # Probability of Alzheimer\\n\\n# --- Neural Network prediction ---\\nnn_prob = nn_model.predict(features_scaled)[0][0]\\nnn_pred = int(nn_prob > 0.5)\\n\\nlabel_map = {0: \"Healthy\", 1: \"Alzheimer\"}\\n\\nprint(\"🧩 Random Forest Prediction:\", label_map[rf_pred], f\"(Confidence: {rf_confidence:.2f})\")\\nprint(\"🧠 Neural Network Prediction:\", label_map[nn_pred], f\"(Confidence: {nn_prob:.2f})\")\\n\\n# --- Automatically choose the more accurate model ---\\nif rf_accuracy >= nn_accuracy:\\n    final_model = \"Random Forest\"\\n    final_pred = rf_pred\\nelse:\\n    final_model = \"Neural Network\"\\n    final_pred = nn_pred\\n\\nprint(f\"\\n🏆 FINAL DECISION (Based on {final_model} - higher accuracy): {label_map[final_pred]}\")\\n\\n'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# =============================\n",
    "# Step 6 — Make Predictions\n",
    "# =============================\n",
    "import json\n",
    "\n",
    "# --- Load model accuracies ---\n",
    "with open(\"D:/University/AI/Project/Alzheimer Speech Detection/models/accuracies.json\", \"r\") as f:\n",
    "    accuracies = json.load(f)\n",
    "\n",
    "rf_accuracy = accuracies[\"random_forest\"]\n",
    "nn_accuracy = accuracies[\"neural_network\"]\n",
    "\n",
    "# --- Random Forest prediction ---\n",
    "rf_pred = rf_model.predict(features_scaled)[0]\n",
    "rf_confidence = rf_model.predict_proba(features_scaled)[0][1]  # Probability of Alzheimer\n",
    "\n",
    "# --- Neural Network prediction ---\n",
    "nn_prob = nn_model.predict(features_scaled)[0][0]\n",
    "nn_pred = int(nn_prob > 0.5)\n",
    "\n",
    "label_map = {0: \"Healthy\", 1: \"Alzheimer\"}\n",
    "\n",
    "print(\"🧩 Random Forest Prediction:\", label_map[rf_pred], f\"(Confidence: {rf_confidence:.2f})\")\n",
    "print(\"🧠 Neural Network Prediction:\", label_map[nn_pred], f\"(Confidence: {nn_prob:.2f})\")\n",
    "\n",
    "# --- Automatically choose the more accurate model ---\n",
    "if rf_accuracy >= nn_accuracy:\n",
    "    final_model = \"Random Forest\"\n",
    "    final_pred = rf_pred\n",
    "else:\n",
    "    final_model = \"Neural Network\"\n",
    "    final_pred = nn_pred\n",
    "\n",
    "print(f\"\\n🏆 FINAL DECISION (Based on {final_model} - higher accuracy): {label_map[final_pred]}\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec667fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧩 Random Forest Prediction: Healthy (Confidence: 0.49)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# --- Final decision ---\\nif rf_pred != nn_pred:\\n    final_pred = rf_pred if rf_prob > nn_prob else nn_pred\\nelse:\\n    final_pred = rf_pred\\n\\n'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# =============================\n",
    "# Step 6 — Make Predictions\n",
    "# =============================\n",
    "\n",
    "# --- Random Forest prediction ---\n",
    "rf_prob = rf_model.predict_proba(features_scaled)[0][1]  # probability of Alzheimer\n",
    "rf_threshold = 0.6  # adjust based on validation\n",
    "rf_pred = int(rf_prob > rf_threshold)\n",
    "\n",
    "\"\"\" ---\n",
    "# --- Neural Network prediction ---\n",
    "nn_prob = nn_model.predict(features_scaled)[0][0]  # probability of Alzheimer\n",
    "nn_threshold = 0.6\n",
    "nn_pred = int(nn_prob > nn_threshold)\n",
    "--- \"\"\"\n",
    "\n",
    "# --- Label mapping ---\n",
    "label_map = {0: \"Healthy\", 1: \"Alzheimer\"}\n",
    "\n",
    "print(f\"🧩 Random Forest Prediction: {label_map[rf_pred]} (Confidence: {rf_prob:.2f})\")\n",
    "# print(f\"🧠 Neural Network Prediction: {label_map[nn_pred]} (Confidence: {nn_prob:.2f})\")\n",
    "\n",
    "\"\"\" ---\n",
    "# --- Final decision ---\n",
    "if rf_pred != nn_pred:\n",
    "    final_pred = rf_pred if rf_prob > nn_prob else nn_pred\n",
    "else:\n",
    "    final_pred = rf_pred\n",
    "---\"\"\"\n",
    "\n",
    "\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "57257fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# Step 1 — Imports\n",
    "# =============================\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from joblib import load\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7111c252",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# =============================\n",
    "# Step 2 — Load Models and Scaler\n",
    "# =============================\n",
    "MODEL_DIR = \"D:/University/AI/Project/Alzheimer Speech Detection/models\"\n",
    "scaler = load(os.path.join(MODEL_DIR, \"scaler.joblib\"))\n",
    "rf_model = load(os.path.join(MODEL_DIR, \"rf_alz_model.joblib\"))\n",
    "nn_model = load_model(os.path.join(MODEL_DIR, \"nn_alz_model.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "53ad8b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# Step 3 — Feature Extraction\n",
    "# =============================\n",
    "def extract_features(y, sr):\n",
    "    \"\"\"\n",
    "    Extract 65 features from audio: 13 MFCC + 52 linguistic\n",
    "    Replace the linguistic features part with your implementation\n",
    "    \"\"\"\n",
    "    # --- MFCCs ---\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    mfccs_mean = np.mean(mfccs, axis=1)\n",
    "\n",
    "    # --- Placeholder for 52 linguistic features ---\n",
    "    linguistic_features = np.zeros(52)  # Replace with real extraction if available\n",
    "\n",
    "    features = np.concatenate([mfccs_mean, linguistic_features])\n",
    "    \n",
    "    # Pad or truncate to ensure length = 65\n",
    "    expected_len = 65\n",
    "    if len(features) < expected_len:\n",
    "        features = np.pad(features, (0, expected_len - len(features)), 'constant')\n",
    "    elif len(features) > expected_len:\n",
    "        features = features[:expected_len]\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8e4e2784",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================\n",
    "# Step 4 — Ensemble Prediction\n",
    "# =============================\n",
    "def predict_alzheimer_from_audio(audio_path, scaler, rf_model, nn_model, rf_threshold=0.6, nn_threshold=0.6):\n",
    "    # Load audio\n",
    "    y, sr = librosa.load(audio_path, sr=22050)\n",
    "    \n",
    "    # Extract features\n",
    "    features = extract_features(y, sr)\n",
    "    \n",
    "    # Scale features\n",
    "    features_scaled = scaler.transform([features])\n",
    "    \n",
    "    # Random Forest\n",
    "    rf_prob = rf_model.predict_proba(features_scaled)[0][1]\n",
    "    rf_pred = int(rf_prob > rf_threshold)\n",
    "    \n",
    "    # Neural Network\n",
    "    nn_prob = nn_model.predict(features_scaled)[0][0]\n",
    "    nn_pred = int(nn_prob > nn_threshold)\n",
    "    \n",
    "    # Ensemble: majority vote with confidence tie-break\n",
    "    if rf_pred != nn_pred:\n",
    "        final_pred = rf_pred if rf_prob > nn_prob else nn_pred\n",
    "    else:\n",
    "        final_pred = rf_pred\n",
    "    \n",
    "    label_map = {0: \"Healthy\", 1: \"Alzheimer\"}\n",
    "    return label_map[final_pred], rf_prob, nn_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4c075c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\m\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step\n",
      "\n",
      "Random Forest Prediction: Healthy (Confidence: 0.57)\n",
      "Neural Network Prediction: Healthy (Confidence: 0.33)\n",
      "\n",
      "Ensemble Final Prediction: Healthy\n"
     ]
    }
   ],
   "source": [
    "# =============================\n",
    "# Step 5 — Example Usage\n",
    "# =============================\n",
    "\n",
    "audio_file = \"D:/University/AI/Project/Alzheimer Speech Detection/data/audio_files/19-198-0000.wav\"  # replace with your audio path\n",
    "final_pred, rf_prob, nn_prob = predict_alzheimer_from_audio(audio_file, scaler, rf_model, nn_model)\n",
    "\n",
    "# Individual model predictions\n",
    "rf_pred = \"Alzheimer\" if rf_prob > 0.6 else \"Healthy\"\n",
    "nn_pred = \"Alzheimer\" if nn_prob > 0.6 else \"Healthy\"\n",
    "\n",
    "print()\n",
    "\n",
    "print(f\"Random Forest Prediction: {rf_pred} (Confidence: {rf_prob:.2f})\")\n",
    "print(f\"Neural Network Prediction: {nn_pred} (Confidence: {nn_prob:.2f})\")\n",
    "print()\n",
    "print(f\"Ensemble Final Prediction: {final_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996372df",
   "metadata": {},
   "source": [
    "# 🔍 Explanation\n",
    "\n",
    "1. **Feature Extraction** — We compute MFCC, chroma, spectral contrast, and zero-crossing features from the input `.wav` file.  \n",
    "2. **Feature Padding** — Since the original model was trained on 65 features (MFCC + linguistic), we pad or trim the feature vector to match that length.  \n",
    "3. **Scaling** — The features are normalized using the same `StandardScaler` used during training.  \n",
    "4. **Prediction** — Both Random Forest and Neural Network models predict whether the speech indicates Alzheimer’s or not.  \n",
    "5. **Output** — The notebook prints the classification (“Healthy” or “Alzheimer”).  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
